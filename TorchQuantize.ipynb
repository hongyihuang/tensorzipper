{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempted to use PyTorch quantization routines, but failed with tons of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import struct\n",
    "import gzip\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "\n",
    "m = nn.AvgPool2d(2, stride=2)\n",
    "x_train = m(x_train.reshape((50000, 28, 28))).reshape((50000, 14 * 14))\n",
    "x_valid = m(x_valid.reshape((10000, 28, 28))).reshape((10000, 14 * 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STE_Round(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        # Because we are saving one of the inputs use `save_for_backward`\n",
    "        # Save non-tensors and non-inputs/non-outputs directly on ctx\n",
    "        return torch.round(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        # A function support double backward automatically if autograd\n",
    "        # is able to record the computations performed in backward\n",
    "        return grad_out\n",
    "\n",
    "def Q(x, s, z, alpha_q, beta_q):\n",
    "  # WARNING TORCH.ROUND BACKPROP GIVES 0, SHOULD USE STE\n",
    "  x_q = STE_Round.apply(1/s*x+z)\n",
    "  #x_q = 1/s * x + z\n",
    "  return torch.clamp(x_q, min=alpha_q, max=beta_q)\n",
    "\n",
    "def Q_int8(x, s, z):\n",
    "  x_q = Q(x, s, z, alpha_q = -127, beta_q = 127)\n",
    "  return x_q\n",
    "\n",
    "def Q_uint8(x, s, z):\n",
    "  x_q = Q(x, s, z, alpha_q = 0, beta_q = 255)\n",
    "  return x_q\n",
    "\n",
    "def Q_inv(x_q, s, z):\n",
    "  return s * (x_q - z)\n",
    "\n",
    "def Q_matmul_s_only(x, w, s_x, s_w):\n",
    "  return (x @ w) * s_x * s_w\n",
    "\n",
    "def FQ_int8(x, s, z):\n",
    "  return Q_inv(Q_int8(x, s, z), s, z)\n",
    "\n",
    "def FQ(x, s, z, bins):\n",
    "  return Q_inv(Q(x, s, z, alpha_q = -bins, beta_q = bins), s, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 196])\n",
      "tensor(0) tensor(9)\n",
      "torch.Size([50000, 196])\n",
      "torch.Size([10000, 196])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((round(math.sqrt(c)), round(math.sqrt(c)))), cmap=\"gray\")\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Q_int8(x_train, torch.max(torch.abs(x_train))/(16-1), 0)\n",
    "x_valid = Q_int8(x_valid, torch.max(torch.abs(x_valid))/(16-1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(nn.Module):\n",
    "  def __init__(self, h1):\n",
    "    super().__init__()\n",
    "    self.quant = torch.ao.quantization.QuantStub()\n",
    "    self.l1 = nn.Linear(c, h1)\n",
    "    self.l2 = nn.Linear(h1, 10)\n",
    "    self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "    #self.l3 = FC_Q(10, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.relu = torch.nn.ReLU6()\n",
    "    self.softmax = torch.nn.Softmax(dim=1)\n",
    "    x = self.quant(x)\n",
    "    x = self.relu(self.l1(x))\n",
    "    x = self.dequant(x)\n",
    "\n",
    "    x = self.quant(x)\n",
    "    x = self.softmax(self.l2(x))\n",
    "    x = self.dequant(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = 64\n",
    "m = nn.Sequential(\n",
    "  nn.Linear(c, h1),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(h1, 10),\n",
    "  nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp = M(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'M' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Fuse\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39;49mao\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mfuse_modules(model_fp, [[\u001b[39m'\u001b[39;49m\u001b[39mlinear\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m]]) \u001b[39m# fuse first Linear-ReLU pair\u001b[39;00m\n\u001b[1;32m      3\u001b[0m torch\u001b[39m.\u001b[39mao\u001b[39m.\u001b[39mquantization\u001b[39m.\u001b[39mfuse_modules(model_fp, [[\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m]]) \u001b[39m# fuse second Linear-Softmax pair\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"Insert stubs\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/fuse_modules.py:158\u001b[0m, in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse_modules\u001b[39m(model, modules_to_fuse, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fuser_func\u001b[39m=\u001b[39mfuse_known_modules, fuse_custom_config_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Fuses a list of modules into a single module\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    Fuses only the following sequence of modules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m _fuse_modules(\n\u001b[1;32m    159\u001b[0m         model,\n\u001b[1;32m    160\u001b[0m         modules_to_fuse,\n\u001b[1;32m    161\u001b[0m         is_qat\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    162\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    163\u001b[0m         fuser_func\u001b[39m=\u001b[39;49mfuser_func,\n\u001b[1;32m    164\u001b[0m         fuse_custom_config_dict\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/fuse_modules.py:100\u001b[0m, in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# Handle case of modules_to_fuse being a list of lists\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mfor\u001b[39;00m module_list \u001b[39min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m--> 100\u001b[0m         _fuse_modules_helper(model, module_list, is_qat, fuser_func, fuse_custom_config_dict)\n\u001b[1;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/fuse_modules.py:81\u001b[0m, in \u001b[0;36m_fuse_modules_helper\u001b[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     79\u001b[0m mod_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m---> 81\u001b[0m     mod_list\u001b[39m.\u001b[39mappend(_get_module(model, item))\n\u001b[1;32m     83\u001b[0m \u001b[39m# Fuse list of modules\u001b[39;00m\n\u001b[1;32m     84\u001b[0m new_mod_list \u001b[39m=\u001b[39m fuser_func(mod_list, is_qat, additional_fuser_method_mapping)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/fuse_modules.py:25\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(model, submodule_key)\u001b[0m\n\u001b[1;32m     23\u001b[0m cur_mod \u001b[39m=\u001b[39m model\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tokens:\n\u001b[0;32m---> 25\u001b[0m     cur_mod \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(cur_mod, s)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m cur_mod\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'M' object has no attribute 'linear'"
     ]
    }
   ],
   "source": [
    "\"\"\"Fuse\"\"\"\n",
    "torch.ao.quantization.fuse_modules(model_fp, [['linear','relu']]) # fuse first Linear-ReLU pair\n",
    "torch.ao.quantization.fuse_modules(model_fp, [['linear','softmax']]) # fuse second Linear-Softmax pair\n",
    "\n",
    "\"\"\"Insert stubs\"\"\"\n",
    "m = nn.Sequential(torch.quantization.QuantStub(), \n",
    "                  *m, \n",
    "                  torch.quantization.DeQuantStub())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): QuantStub()\n",
       "  (l1): Linear(in_features=196, out_features=64, bias=True)\n",
       "  (l2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp.qconfig = torch.ao.quantization.get_default_qat_qconfig('qnnpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp_fused = torch.ao.quantization.fuse_modules(model_fp,\n",
    "    [['l1', 'bn', 'relu']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongyihuang/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/Users/hongyihuang/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/utils.py:310: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::conv2d_prepack NoQEngine",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 57\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# run the training loop (not shown)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m# training_loop(model_fp32_prepared)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# used with each activation tensor, fuses modules where appropriate,\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# and replaces key operators with quantized implementations.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m model_fp32_prepared\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 57\u001b[0m model_int8 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mao\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mconvert(model_fp32_prepared)\n\u001b[1;32m     59\u001b[0m \u001b[39m# run the model, relevant calculations will happen in int8\u001b[39;00m\n\u001b[1;32m     60\u001b[0m res \u001b[39m=\u001b[39m model_int8(input_fp32)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:551\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n\u001b[1;32m    550\u001b[0m     module \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(module)\n\u001b[0;32m--> 551\u001b[0m _convert(\n\u001b[1;32m    552\u001b[0m     module, mapping, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, is_reference\u001b[39m=\u001b[39;49mis_reference,\n\u001b[1;32m    553\u001b[0m     convert_custom_config_dict\u001b[39m=\u001b[39;49mconvert_custom_config_dict)\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m remove_qconfig:\n\u001b[1;32m    555\u001b[0m     _remove_qconfig(module)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:591\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, _FusedModule) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    588\u001b[0m        type_before_parametrizations(mod) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m custom_module_class_mapping:\n\u001b[1;32m    589\u001b[0m         _convert(mod, mapping, \u001b[39mTrue\u001b[39;00m,  \u001b[39m# inplace\u001b[39;00m\n\u001b[1;32m    590\u001b[0m                  is_reference, convert_custom_config_dict)\n\u001b[0;32m--> 591\u001b[0m     reassign[name] \u001b[39m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    593\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m reassign\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    594\u001b[0m     module\u001b[39m.\u001b[39m_modules[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:624\u001b[0m, in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping)\u001b[0m\n\u001b[1;32m    622\u001b[0m         new_mod \u001b[39m=\u001b[39m qmod\u001b[39m.\u001b[39mfrom_float(mod, weight_qparams)\n\u001b[1;32m    623\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m         new_mod \u001b[39m=\u001b[39m qmod\u001b[39m.\u001b[39;49mfrom_float(mod)\n\u001b[1;32m    625\u001b[0m     swapped \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m swapped:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# Preserve module's pre forward hooks. They'll be called on quantized input\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:110\u001b[0m, in \u001b[0;36mConvReLU2d.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(mod) \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mao\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mintrinsic\u001b[39m.\u001b[39mqat\u001b[39m.\u001b[39mConvBnReLU2d:\n\u001b[1;32m    107\u001b[0m     mod\u001b[39m.\u001b[39mweight, mod\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m fuse_conv_bn_weights(\n\u001b[1;32m    108\u001b[0m         mod\u001b[39m.\u001b[39mweight, mod\u001b[39m.\u001b[39mbias, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mrunning_mean, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mrunning_var,\n\u001b[1;32m    109\u001b[0m         mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39meps, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mweight, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mbias)\n\u001b[0;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(ConvReLU2d, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49mfrom_float(mod)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/conv.py:480\u001b[0m, in \u001b[0;36mConv2d.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_float\u001b[39m(\u001b[39mcls\u001b[39m, mod):\n\u001b[1;32m    474\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \n\u001b[1;32m    476\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39m        mod (Module): a float module, either produced by torch.ao.quantization\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[39m          utilities or provided by the user\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConvNd\u001b[39m.\u001b[39;49mfrom_float(\u001b[39mcls\u001b[39;49m, mod)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/conv.py:242\u001b[0m, in \u001b[0;36m_ConvNd.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    240\u001b[0m         mod \u001b[39m=\u001b[39m mod[\u001b[39m0\u001b[39m]\n\u001b[1;32m    241\u001b[0m     weight_post_process \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mqconfig\u001b[39m.\u001b[39mweight()\n\u001b[0;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_qconv(mod, activation_post_process, weight_post_process)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/conv.py:206\u001b[0m, in \u001b[0;36m_ConvNd.get_qconv\u001b[0;34m(cls, mod, activation_post_process, weight_post_process)\u001b[0m\n\u001b[1;32m    204\u001b[0m qweight \u001b[39m=\u001b[39m _quantize_weight(mod\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mfloat(), weight_post_process)\n\u001b[1;32m    205\u001b[0m \u001b[39m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m qconv \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(mod\u001b[39m.\u001b[39;49min_channels, mod\u001b[39m.\u001b[39;49mout_channels, mod\u001b[39m.\u001b[39;49mkernel_size,\n\u001b[1;32m    207\u001b[0m             mod\u001b[39m.\u001b[39;49mstride, mod\u001b[39m.\u001b[39;49mpadding, mod\u001b[39m.\u001b[39;49mdilation, mod\u001b[39m.\u001b[39;49mgroups,\n\u001b[1;32m    208\u001b[0m             mod\u001b[39m.\u001b[39;49mbias \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, mod\u001b[39m.\u001b[39;49mpadding_mode)\n\u001b[1;32m    209\u001b[0m qconv\u001b[39m.\u001b[39mset_weight_bias(qweight, mod\u001b[39m.\u001b[39mbias)\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m activation_post_process \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m activation_post_process\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat:\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:84\u001b[0m, in \u001b[0;36mConvReLU2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, in_channels, out_channels, kernel_size, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     82\u001b[0m              padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, dilation\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, groups\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m              padding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m         in_channels, out_channels, kernel_size, stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m     86\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding, dilation\u001b[39m=\u001b[39;49mdilation, groups\u001b[39m=\u001b[39;49mgroups, bias\u001b[39m=\u001b[39;49mbias,\n\u001b[1;32m     87\u001b[0m         padding_mode\u001b[39m=\u001b[39;49mpadding_mode, device\u001b[39m=\u001b[39;49mdevice, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/conv.py:436\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    433\u001b[0m dilation \u001b[39m=\u001b[39m _pair(dilation)\n\u001b[1;32m    434\u001b[0m \u001b[39m# Subclasses of _ConvNd need to call _init rather than __init__. See\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# discussion on PR #49702\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m    437\u001b[0m     in_channels, out_channels, kernel_size, stride, padding, dilation,\n\u001b[1;32m    438\u001b[0m     \u001b[39mFalse\u001b[39;49;00m, _pair(\u001b[39m0\u001b[39;49m), groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/conv.py:82\u001b[0m, in \u001b[0;36m_ConvNd._init\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     74\u001b[0m qweight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_empty_affine_quantized(\n\u001b[1;32m     75\u001b[0m     weight_shape \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kernel_size),\n\u001b[1;32m     76\u001b[0m     scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, zero_point\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mqint8,\n\u001b[1;32m     77\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m factory_kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m     78\u001b[0m bias_float \u001b[39m=\u001b[39m (\n\u001b[1;32m     79\u001b[0m     torch\u001b[39m.\u001b[39mzeros(out_channels, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat,\n\u001b[1;32m     80\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m factory_kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m}) \u001b[39mif\u001b[39;00m bias \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_weight_bias(qweight, bias_float)\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzero_point \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/conv.py:445\u001b[0m, in \u001b[0;36mConv2d.set_weight_bias\u001b[0;34m(self, w, b)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_weight_bias\u001b[39m(\u001b[39mself\u001b[39m, w: torch\u001b[39m.\u001b[39mTensor, b: Optional[torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mquantized\u001b[39m.\u001b[39;49mconv2d_prepack(\n\u001b[1;32m    446\u001b[0m             w, b, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n\u001b[1;32m    447\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mquantized\u001b[39m.\u001b[39mconv2d_prepack(\n\u001b[1;32m    449\u001b[0m             w, b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "File \u001b[0;32m~/anaconda3/envs/tzip/lib/python3.11/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Didn't find engine for operation quantized::conv2d_prepack NoQEngine"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# define a floating point model where some layers could benefit from QAT\n",
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        self.conv = torch.nn.Conv2d(1, 1, 1)\n",
    "        self.bn = torch.nn.BatchNorm2d(1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        # DeQuantStub converts tensors from quantized to floating point\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# create a model instance\n",
    "model_fp32 = M()\n",
    "\n",
    "# model must be set to eval for fusion to work\n",
    "model_fp32.eval()\n",
    "\n",
    "# attach a global qconfig, which contains information about what kind\n",
    "# of observers to attach. Use 'x86' for server inference and 'qnnpack'\n",
    "# for mobile inference. Other quantization configurations such as selecting\n",
    "# symmetric or asymmetric quantization and MinMax or L2Norm calibration techniques\n",
    "# can be specified here.\n",
    "# Note: the old 'fbgemm' is still available but 'x86' is the recommended default\n",
    "# for server inference.\n",
    "# model_fp32.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
    "model_fp32.qconfig = torch.ao.quantization.get_default_qat_qconfig('x86')\n",
    "\n",
    "# fuse the activations to preceding layers, where applicable\n",
    "# this needs to be done manually depending on the model architecture\n",
    "model_fp32_fused = torch.ao.quantization.fuse_modules(model_fp32,\n",
    "    [['conv', 'bn', 'relu']])\n",
    "\n",
    "# Prepare the model for QAT. This inserts observers and fake_quants in\n",
    "# the model needs to be set to train for QAT logic to work\n",
    "# the model that will observe weight and activation tensors during calibration.\n",
    "model_fp32_prepared = torch.ao.quantization.prepare_qat(model_fp32_fused.train())\n",
    "\n",
    "# run the training loop (not shown)\n",
    "# training_loop(model_fp32_prepared)\n",
    "\n",
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, fuses modules where appropriate,\n",
    "# and replaces key operators with quantized implementations.\n",
    "model_fp32_prepared.eval()\n",
    "model_int8 = torch.ao.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "# run the model, relevant calculations will happen in int8\n",
    "res = model_int8(input_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tzip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
